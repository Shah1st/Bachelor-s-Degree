{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torchdiffeq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:25:20.124873Z","iopub.execute_input":"2025-02-21T22:25:20.125143Z","iopub.status.idle":"2025-02-21T22:25:24.686802Z","shell.execute_reply.started":"2025-02-21T22:25:20.125122Z","shell.execute_reply":"2025-02-21T22:25:24.685828Z"}},"outputs":[{"name":"stdout","text":"Collecting torchdiffeq\n  Downloading torchdiffeq-0.2.5-py3-none-any.whl.metadata (440 bytes)\nRequirement already satisfied: torch>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (2.5.1+cu121)\nRequirement already satisfied: scipy>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from torchdiffeq) (1.13.1)\nRequirement already satisfied: numpy<2.3,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from scipy>=1.4.0->torchdiffeq) (1.26.4)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.5.0->torchdiffeq) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.5.0->torchdiffeq) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (2.4.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.5.0->torchdiffeq) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.3,>=1.22.4->scipy>=1.4.0->torchdiffeq) (2024.2.0)\nDownloading torchdiffeq-0.2.5-py3-none-any.whl (32 kB)\nInstalling collected packages: torchdiffeq\nSuccessfully installed torchdiffeq-0.2.5\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install torchcfm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:25:24.687960Z","iopub.execute_input":"2025-02-21T22:25:24.688272Z","iopub.status.idle":"2025-02-21T22:25:41.422342Z","shell.execute_reply.started":"2025-02-21T22:25:24.688238Z","shell.execute_reply":"2025-02-21T22:25:41.421508Z"}},"outputs":[{"name":"stdout","text":"Collecting torchcfm\n  Downloading torchcfm-1.0.5-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from torchcfm) (2.5.1+cu121)\nRequirement already satisfied: torchvision>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from torchcfm) (0.20.1+cu121)\nCollecting lightning-bolts (from torchcfm)\n  Downloading lightning_bolts-0.7.0-py3-none-any.whl.metadata (9.5 kB)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from torchcfm) (3.7.5)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchcfm) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torchcfm) (1.13.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torchcfm) (1.2.2)\nCollecting scprep (from torchcfm)\n  Downloading scprep-1.2.3-py3-none-any.whl.metadata (7.0 kB)\nCollecting scanpy (from torchcfm)\n  Downloading scanpy-1.11.0-py3-none-any.whl.metadata (9.5 kB)\nCollecting torchdyn (from torchcfm)\n  Downloading torchdyn-1.0.6-py3-none-any.whl.metadata (891 bytes)\nCollecting pot (from torchcfm)\n  Downloading POT-0.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (34 kB)\nRequirement already satisfied: torchdiffeq in /usr/local/lib/python3.10/dist-packages (from torchcfm) (0.2.5)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from torchcfm) (1.4.0)\nCollecting clean-fid (from torchcfm)\n  Downloading clean_fid-0.1.35-py3-none-any.whl.metadata (36 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->torchcfm) (3.17.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->torchcfm) (4.12.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->torchcfm) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->torchcfm) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->torchcfm) (2024.12.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->torchcfm) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->torchcfm) (1.3.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.11.0->torchcfm) (11.0.0)\nRequirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.10/dist-packages (from clean-fid->torchcfm) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from clean-fid->torchcfm) (2.32.3)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->torchcfm) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->torchcfm) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->torchcfm) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->torchcfm) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->torchcfm) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->torchcfm) (2.4.1)\nCollecting pytorch-lightning<2.0.0,>1.7.0 (from lightning-bolts->torchcfm)\n  Downloading pytorch_lightning-1.9.5-py3-none-any.whl.metadata (23 kB)\nRequirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (from lightning-bolts->torchcfm) (1.6.1)\nRequirement already satisfied: lightning-utilities>0.3.1 in /usr/local/lib/python3.10/dist-packages (from lightning-bolts->torchcfm) (0.12.0)\nRequirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from lightning-bolts->torchcfm) (2.17.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchcfm) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchcfm) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchcfm) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchcfm) (1.4.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchcfm) (24.2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchcfm) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->torchcfm) (2.9.0.post0)\nCollecting anndata>=0.8 (from scanpy->torchcfm)\n  Downloading anndata-0.11.3-py3-none-any.whl.metadata (8.2 kB)\nRequirement already satisfied: h5py>=3.7 in /usr/local/lib/python3.10/dist-packages (from scanpy->torchcfm) (3.12.1)\nRequirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from scanpy->torchcfm) (1.4.2)\nCollecting legacy-api-wrap>=1.4 (from scanpy->torchcfm)\n  Downloading legacy_api_wrap-1.4.1-py3-none-any.whl.metadata (2.1 kB)\nRequirement already satisfied: natsort in /usr/local/lib/python3.10/dist-packages (from scanpy->torchcfm) (8.4.0)\nRequirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from scanpy->torchcfm) (0.60.0)\nRequirement already satisfied: pandas>=1.5 in /usr/local/lib/python3.10/dist-packages (from scanpy->torchcfm) (2.2.3)\nRequirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scanpy->torchcfm) (1.0.1)\nCollecting pynndescent>=0.5 (from scanpy->torchcfm)\n  Downloading pynndescent-0.5.13-py3-none-any.whl.metadata (6.8 kB)\nCollecting seaborn>=0.13 (from scanpy->torchcfm)\n  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\nCollecting session-info2 (from scanpy->torchcfm)\n  Downloading session_info2-0.1.2-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from scanpy->torchcfm) (0.14.4)\nCollecting umap-learn!=0.5.0,>=0.5 (from scanpy->torchcfm)\n  Downloading umap_learn-0.5.7-py3-none-any.whl.metadata (21 kB)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torchcfm) (3.5.0)\nRequirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from scprep->torchcfm) (4.4.2)\nCollecting pandas>=1.5 (from scanpy->torchcfm)\n  Downloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\nRequirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from torchdyn->torchcfm) (5.5.6)\nRequirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from torchdyn->torchcfm) (8.1.5)\nCollecting poethepoet<0.11.0,>=0.10.0 (from torchdyn->torchcfm)\n  Downloading poethepoet-0.10.0-py3-none-any.whl.metadata (12 kB)\nCollecting torchcde<0.3.0,>=0.2.3 (from torchdyn->torchcfm)\n  Downloading torchcde-0.2.5-py3-none-any.whl.metadata (18 kB)\nCollecting torchsde (from torchdyn->torchcfm)\n  Downloading torchsde-0.2.6-py3-none-any.whl.metadata (5.3 kB)\nCollecting array-api-compat!=1.5,>1.4 (from anndata>=0.8->scanpy->torchcfm)\n  Downloading array_api_compat-1.10.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anndata>=0.8->scanpy->torchcfm) (1.2.2)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>0.3.1->lightning-bolts->torchcfm) (75.1.0)\nRequirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->scanpy->torchcfm) (0.43.0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy->torchcfm) (2025.1)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5->scanpy->torchcfm) (2025.1)\nCollecting pastel<0.3.0,>=0.2.0 (from poethepoet<0.11.0,>=0.10.0->torchdyn->torchcfm)\n  Downloading pastel-0.2.1-py2.py3-none-any.whl.metadata (1.9 kB)\nCollecting tomlkit<1.0.0,>=0.6.0 (from poethepoet<0.11.0,>=0.10.0->torchdyn->torchcfm)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->torchcfm) (1.17.0)\nRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (6.0.2)\nRequirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->lightning-bolts->torchcfm) (1.68.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->lightning-bolts->torchcfm) (3.7)\nRequirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->lightning-bolts->torchcfm) (3.20.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->lightning-bolts->torchcfm) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->lightning-bolts->torchcfm) (3.1.3)\nCollecting trampoline>=0.1.2 (from torchsde->torchdyn->torchcfm)\n  Downloading trampoline-0.1.2-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->torchdyn->torchcfm) (0.2.0)\nRequirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->torchdyn->torchcfm) (7.34.0)\nRequirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->torchdyn->torchcfm) (5.7.1)\nRequirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->torchdyn->torchcfm) (8.6.3)\nRequirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->torchdyn->torchcfm) (6.3.3)\nRequirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->torchdyn->torchcfm) (0.2.2)\nRequirement already satisfied: widgetsnbextension~=4.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->torchdyn->torchcfm) (4.0.13)\nRequirement already satisfied: jupyterlab-widgets~=3.0.12 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->torchdyn->torchcfm) (3.0.13)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->torchcfm) (3.0.2)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchcfm) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->torchcfm) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->torchcfm) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->torchcfm) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid->torchcfm) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid->torchcfm) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid->torchcfm) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->clean-fid->torchcfm) (2025.1.31)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (3.11.12)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->torchcfm) (2024.2.0)\nRequirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (0.19.2)\nRequirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (0.7.5)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (3.0.48)\nRequirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (2.19.1)\nRequirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (0.2.0)\nRequirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (0.1.7)\nRequirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (4.9.0)\nRequirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->torchdyn->torchcfm) (5.7.2)\nRequirement already satisfied: pyzmq>=23.0 in /usr/local/lib/python3.10/dist-packages (from jupyter-client->ipykernel->torchdyn->torchcfm) (24.0.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (2.4.6)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (5.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (25.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning<2.0.0,>1.7.0->lightning-bolts->torchcfm) (1.18.3)\nRequirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (0.8.4)\nRequirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.10/dist-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-client->ipykernel->torchdyn->torchcfm) (4.3.6)\nRequirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (0.7.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->torchdyn->torchcfm) (0.2.13)\nDownloading torchcfm-1.0.5-py3-none-any.whl (29 kB)\nDownloading clean_fid-0.1.35-py3-none-any.whl (26 kB)\nDownloading lightning_bolts-0.7.0-py3-none-any.whl (300 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.8/300.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading POT-0.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (865 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.6/865.6 kB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scanpy-1.11.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading scprep-1.2.3-py3-none-any.whl (94 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchdyn-1.0.6-py3-none-any.whl (58 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading anndata-0.11.3-py3-none-any.whl (142 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.7/142.7 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading legacy_api_wrap-1.4.1-py3-none-any.whl (10.0 kB)\nDownloading pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m109.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading poethepoet-0.10.0-py3-none-any.whl (31 kB)\nDownloading pynndescent-0.5.13-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pytorch_lightning-1.9.5-py3-none-any.whl (829 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m829.5/829.5 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchcde-0.2.5-py3-none-any.whl (28 kB)\nDownloading torchsde-0.2.6-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading umap_learn-0.5.7-py3-none-any.whl (88 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.8/88.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading session_info2-0.1.2-py3-none-any.whl (14 kB)\nDownloading array_api_compat-1.10.0-py3-none-any.whl (50 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pastel-0.2.1-py2.py3-none-any.whl (6.0 kB)\nDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading trampoline-0.1.2-py3-none-any.whl (5.2 kB)\nInstalling collected packages: trampoline, tomlkit, session-info2, pastel, legacy-api-wrap, array-api-compat, poethepoet, torchsde, pynndescent, pandas, umap-learn, torchcde, seaborn, pytorch-lightning, anndata, torchdyn, scprep, scanpy, pot, lightning-bolts, clean-fid, torchcfm\n  Attempting uninstall: pandas\n    Found existing installation: pandas 2.2.3\n    Uninstalling pandas-2.2.3:\n      Successfully uninstalled pandas-2.2.3\n  Attempting uninstall: seaborn\n    Found existing installation: seaborn 0.12.2\n    Uninstalling seaborn-0.12.2:\n      Successfully uninstalled seaborn-0.12.2\n  Attempting uninstall: pytorch-lightning\n    Found existing installation: pytorch-lightning 2.5.0.post0\n    Uninstalling pytorch-lightning-2.5.0.post0:\n      Successfully uninstalled pytorch-lightning-2.5.0.post0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngoogle-colab 1.0.0 requires notebook==6.5.5, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.0.3 which is incompatible.\nmizani 0.13.1 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\nmlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nplotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\nplotnine 0.14.4 requires pandas>=2.2.0, but you have pandas 2.0.3 which is incompatible.\ntensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\nxarray 2024.11.0 requires pandas>=2.1, but you have pandas 2.0.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed anndata-0.11.3 array-api-compat-1.10.0 clean-fid-0.1.35 legacy-api-wrap-1.4.1 lightning-bolts-0.7.0 pandas-2.0.3 pastel-0.2.1 poethepoet-0.10.0 pot-0.9.5 pynndescent-0.5.13 pytorch-lightning-1.9.5 scanpy-1.11.0 scprep-1.2.3 seaborn-0.13.2 session-info2-0.1.2 tomlkit-0.13.2 torchcde-0.2.5 torchcfm-1.0.5 torchdyn-1.0.6 torchsde-0.2.6 trampoline-0.1.2 umap-learn-0.5.7\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport sys\nimport copy\nimport torch\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm import trange\nfrom torchdiffeq import odeint\nfrom torchdyn.core import NeuralODE\nfrom torchvision import transforms\nfrom torchvision.utils import save_image, make_grid\n\n# Import the UNet wrapper and conditional flow matching classes\nfrom torchcfm.models.unet.unet import UNetModelWrapper\nfrom torchcfm.conditional_flow_matching import (\n    ConditionalFlowMatcher,\n    ExactOptimalTransportConditionalFlowMatcher,\n    TargetConditionalFlowMatcher,\n    VariancePreservingConditionalFlowMatcher,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:25:41.423879Z","iopub.execute_input":"2025-02-21T22:25:41.424096Z","iopub.status.idle":"2025-02-21T22:26:05.609526Z","shell.execute_reply.started":"2025-02-21T22:25:41.424077Z","shell.execute_reply":"2025-02-21T22:26:05.608865Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# ----------------- Global Variables -----------------\n# Paths to the HAM10000 dataset (adjust as needed)\nCSV_PATH = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv\"\nFOLDER1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\"\nFOLDER2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\"\n\n#PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n\n# Image and model parameters\nIMAGE_SIZE = 128  # Increase resolution if desired\nNUM_CHANNEL = 128\nMODEL_TYPE = \"otcfm\"  # Options: \"otcfm\", \"icfm\", \"fm\", \"si\"\n\n# Training parameters\nLR = 2e-4\nGRAD_CLIP = 1.0\nTOTAL_STEPS = 400001\nWARMUP = 5000\nBATCH_SIZE = 8\nNUM_WORKERS = 4\nEMA_DECAY = 0.9999\nSAVE_STEP = 20000\n\n# Evaluation / integration parameters\nINTEGRATION_STEPS = 100\nINTEGRATION_METHOD = \"dopri5\"  # Use \"euler\" to use NeuralODE wrapper instead of odeint\nTOL = 1e-5\nBATCH_SIZE_FID = 64\nNUM_GEN = 5000  # Number of images to generate for FID evaluation\n\n# Action: set to \"train\" to run training, or \"fid\" to run FID evaluation\nACTION = \"train\"  # or \"fid\"\n\n# Option to use a small subset for quick experiments\nUSE_SMALL_SUBSET = True\nif USE_SMALL_SUBSET:\n    TOTAL_STEPS = 5001        # Fewer training steps\n    SAVE_STEP = 1000          # Save checkpoints more frequently for testing\n    NUM_GEN = 50              # Generate only a few images\n\n# ----------------- Device -----------------\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda:0\" if use_cuda else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:29:31.857587Z","iopub.execute_input":"2025-02-21T22:29:31.857888Z","iopub.status.idle":"2025-02-21T22:29:31.886310Z","shell.execute_reply.started":"2025-02-21T22:29:31.857866Z","shell.execute_reply":"2025-02-21T22:29:31.885666Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"\n\n\n\n\n\n# ----------------- Custom Dataset for HAM10000 -----------------\nclass Ham10000Dataset(torch.utils.data.Dataset):\n    def __init__(self, csv_path, folder1, folder2, transform=None):\n        self.df = pd.read_csv(csv_path)\n        # Map lesion types to binary labels: 0 for benign, 1 for malignant\n        benign_types = ['nv', 'bkl', 'akiec', 'vasc', 'df']\n        malignant_types = ['mel', 'bcc']\n        self.df['target'] = self.df['dx'].apply(lambda x: 0 if x in benign_types else 1)\n        self.folder1 = folder1\n        self.folder2 = folder2\n        self.transform = transform\n        # Compute image paths\n        self.df['image_path'] = self.df['image_id'].apply(self.get_image_path)\n        # Remove rows with missing images\n        self.df = self.df[self.df['image_path'].notnull()].reset_index(drop=True)\n        \n        # For quick experiments, optionally use only a small subset of the data.\n        if USE_SMALL_SUBSET:\n            subset_size = min(1000, len(self.df))\n            self.df = self.df.iloc[:subset_size].reset_index(drop=True)\n\n    def get_image_path(self, image_id):\n        filename = f\"{image_id}.jpg\"\n        path1 = os.path.join(self.folder1, filename)\n        path2 = os.path.join(self.folder2, filename)\n        if os.path.exists(path1):\n            return path1\n        elif os.path.exists(path2):\n            return path2\n        else:\n            return None\n\n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img = Image.open(row['image_path']).convert(\"RGB\")\n        if self.transform is not None:\n            img = self.transform(img)\n        label = torch.tensor(row['target'], dtype=torch.long)\n        return img, label\n\n# ----------------- Data Transforms -----------------\ntransform_train = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\ntransform_fid = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n# ----------------- Model Setup -----------------\nnet_model = UNetModelWrapper(\n    dim=(3, IMAGE_SIZE, IMAGE_SIZE),\n    num_res_blocks=2,\n    num_channels=NUM_CHANNEL,\n    channel_mult=[1, 2, 2, 2],\n    num_heads=4,\n    num_head_channels=64,\n    attention_resolutions=\"16\",\n    dropout=0.1,\n).to(device)\n\nema_model = copy.deepcopy(net_model)\n\n# ----------------- Define Flow Matcher -----------------\nsigma = 0.0\nif MODEL_TYPE == \"otcfm\":\n    FM = ExactOptimalTransportConditionalFlowMatcher(sigma=sigma)\nelif MODEL_TYPE == \"icfm\":\n    FM = ConditionalFlowMatcher(sigma=sigma)\nelif MODEL_TYPE == \"fm\":\n    FM = TargetConditionalFlowMatcher(sigma=sigma)\nelif MODEL_TYPE == \"si\":\n    FM = VariancePreservingConditionalFlowMatcher(sigma=sigma)\nelse:\n    raise NotImplementedError(f\"Unknown model type {MODEL_TYPE}\")\n\n# ----------------- Utility Functions -----------------\ndef ema_update(source, target, decay):\n    source_dict = source.state_dict()\n    target_dict = target.state_dict()\n    for key in source_dict.keys():\n        target_dict[key].data.copy_(target_dict[key].data * decay + source_dict[key].data * (1 - decay))\n\ndef infiniteloop(dataloader):\n    while True:\n        for data in dataloader:\n            yield data\n\ndef generate_samples(model, savedir, step):\n    model.eval()\n    model_ = copy.deepcopy(model)\n    if hasattr(model_, \"module\"):\n        model_ = model_.module.to(device)\n    # Use NeuralODE with Euler if desired\n    node_ = NeuralODE(model_, solver=\"euler\", sensitivity=\"adjoint\")\n    with torch.no_grad():\n        noise = torch.randn(64, 3, IMAGE_SIZE, IMAGE_SIZE, device=device)\n        # Generate random binary conditions for each sample\n        t_span = torch.linspace(0, 1, 100, device=device)\n        # Assumes the model forward supports a \"condition\" argument.\n        traj = node_.trajectory(noise, t_span=t_span)\n        traj = traj[-1, :].view([-1, 3, IMAGE_SIZE, IMAGE_SIZE]).clamp(-1, 1)\n        traj = traj / 2 + 0.5\n    os.makedirs(savedir, exist_ok=True)\n    save_image(traj, os.path.join(savedir, f\"generated_FM_images_step_{step}.png\"), nrow=8)\n    model.train()\n\n# ----------------- Training Function -----------------\ndef train():\n    print(\"Starting training...\")\n    print(\"Learning rate:\", LR)\n    print(\"Total steps:\", TOTAL_STEPS)\n    print(\"EMA decay:\", EMA_DECAY)\n    print(\"Save step:\", SAVE_STEP)\n    \n    # Create the HAM10000 dataset and use an 80% train split\n    dataset_full = Ham10000Dataset(CSV_PATH, FOLDER1, FOLDER2, transform=transform_train)\n    split_idx = int(0.8 * len(dataset_full))\n    dataset_train = torch.utils.data.Subset(dataset_full, list(range(split_idx)))\n    \n    dataloader = torch.utils.data.DataLoader(\n        dataset_train,\n        batch_size=BATCH_SIZE,\n        shuffle=True,\n        num_workers=NUM_WORKERS,\n        drop_last=True,\n    )\n    datalooper = infiniteloop(dataloader)\n    \n    optim = torch.optim.Adam(net_model.parameters(), lr=LR)\n    sched = torch.optim.lr_scheduler.LambdaLR(optim, lr_lambda=lambda step: min(step, WARMUP) / WARMUP)\n    \n    # Display model size\n    model_size = sum(p.data.nelement() for p in net_model.parameters())\n    print(\"Model parameters: %.2f M\" % (model_size / 1e6))\n\n    pbar = trange(TOTAL_STEPS, desc=\"Training\", ncols=80)\n\n    # Training loop\n    for step in pbar:\n        optim.zero_grad()\n        # Get both image and label (used as the condition)\n        x1, cond = next(datalooper)\n        x1 = x1.to(device)\n        cond = cond.to(device)\n        # Create noise input with same shape as x1\n        x0 = torch.randn_like(x1)\n        # Get time, intermediate state, and target flow\n        t, xt, ut = FM.sample_location_and_conditional_flow(x0, x1)\n        # Forward pass (assumes the model supports a \"condition\" argument)\n        vt = net_model(t, xt)\n        loss = torch.mean((vt - ut) ** 2)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(net_model.parameters(), GRAD_CLIP)\n        optim.step()\n        sched.step()\n        ema_update(net_model, ema_model, EMA_DECAY)\n        \n        torch.cuda.empty_cache()\n\n        \n        if step % 100 == 0:\n            trange_desc = f\"Step {step} Loss {loss.item():.4f}\"\n            pbar.write(trange_desc)\n        \n        # Save checkpoint and generated samples at intervals\n        if SAVE_STEP > 0 and step % SAVE_STEP == 0:\n            save_dir = os.path.join(\"./results/\", MODEL_TYPE)\n            os.makedirs(save_dir, exist_ok=True)\n            generate_samples(net_model, save_dir, step)\n            generate_samples(ema_model, save_dir, step)\n            torch.save(\n                {\n                    \"net_model\": net_model.state_dict(),\n                    \"ema_model\": ema_model.state_dict(),\n                    \"sched\": sched.state_dict(),\n                    \"optim\": optim.state_dict(),\n                    \"step\": step,\n                },\n                os.path.join(save_dir, f\"{MODEL_TYPE}_ham10000_weights_step_{step}.pt\"),\n            )\n\n# ----------------- FID Evaluation Function -----------------\ndef fid_evaluation():\n    print(\"Starting FID evaluation...\")\n    # Load a checkpoint from the last training step (or adjust as needed)\n    ckpt_path = os.path.join(\"./results/\", MODEL_TYPE, f\"{MODEL_TYPE}_ham10000_weights_step_{TOTAL_STEPS - 1}.pt\")\n    print(\"Loading checkpoint from:\", ckpt_path)\n    checkpoint = torch.load(ckpt_path, map_location=device)\n    state_dict = checkpoint[\"ema_model\"]\n    try:\n        net_model.load_state_dict(state_dict)\n    except RuntimeError:\n        from collections import OrderedDict\n        new_state_dict = OrderedDict()\n        for k, v in state_dict.items():\n            new_state_dict[k[7:]] = v\n        net_model.load_state_dict(new_state_dict)\n    net_model.eval()\n\n    # Define integration for FID generation\n    if INTEGRATION_METHOD == \"euler\":\n        node = NeuralODE(net_model, solver=INTEGRATION_METHOD)\n    else:\n        node = net_model  # We'll wrap the call in odeint\n    \n    def gen_1_img(unused_latent):\n        with torch.no_grad():\n            x = torch.randn(BATCH_SIZE_FID, 3, IMAGE_SIZE, IMAGE_SIZE, device=device)\n            cond = torch.randint(0, 2, (BATCH_SIZE_FID,), device=device)\n            if INTEGRATION_METHOD == \"euler\":\n                t_span = torch.linspace(0, 1, INTEGRATION_STEPS + 1, device=device)\n                traj = node.trajectory(x, t_span=t_span, condition=cond)\n            else:\n                t_span = torch.linspace(0, 1, 2, device=device)\n                traj = odeint(lambda t, x: net_model(t, x, condition=cond),\n                              x, t_span, rtol=TOL, atol=TOL, method=INTEGRATION_METHOD)\n            traj = traj[-1, :]\n            img = (traj * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n            return img\n\n    # In practice, you would compare generated images to a held-out set.\n    # Here we simulate FID evaluation by generating a few images.\n    print(\"Generating images for FID evaluation...\")\n    imgs = gen_1_img(None)\n    print(\"Generated image batch shape:\", imgs.shape)\n    # (Optionally, compute FID using a suitable library or custom implementation.)\n    # For demonstration, we simply print a simulated FID score.\n    fid_score = np.random.uniform(10, 50)\n    print(\"Simulated FID score:\", fid_score)\n\n# ----------------- Main -----------------\ndef main():\n    if ACTION == \"train\":\n        train()\n    elif ACTION == \"fid\":\n        fid_evaluation()\n    else:\n        print(\"Unknown ACTION. Set ACTION to 'train' or 'fid'.\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T22:29:32.573231Z","iopub.execute_input":"2025-02-21T22:29:32.573650Z","iopub.status.idle":"2025-02-21T23:38:00.972659Z","shell.execute_reply.started":"2025-02-21T22:29:32.573614Z","shell.execute_reply":"2025-02-21T23:38:00.971599Z"}},"outputs":[{"name":"stdout","text":"Starting training...\nLearning rate: 0.0002\nTotal steps: 5001\nEMA decay: 0.9999\nSave step: 1000\nModel parameters: 35.75 M\n","output_type":"stream"},{"name":"stderr","text":"Training:   0%|                                        | 0/5001 [00:02<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Step 0 Loss 1.1134\n","output_type":"stream"},{"name":"stderr","text":"Training:   2%|▌                             | 101/5001 [04:09<53:46,  1.52it/s]","output_type":"stream"},{"name":"stdout","text":"Step 100 Loss 1.1154\n","output_type":"stream"},{"name":"stderr","text":"Training:   4%|█▏                            | 201/5001 [05:05<51:51,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Step 200 Loss 0.9233\n","output_type":"stream"},{"name":"stderr","text":"Training:   6%|█▊                            | 301/5001 [06:02<50:58,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Step 300 Loss 0.7322\n","output_type":"stream"},{"name":"stderr","text":"Training:   8%|██▍                           | 401/5001 [06:59<49:58,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Step 400 Loss 0.4720\n","output_type":"stream"},{"name":"stderr","text":"Training:  10%|███                           | 501/5001 [07:55<49:48,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Step 500 Loss 0.3424\n","output_type":"stream"},{"name":"stderr","text":"Training:  12%|███▌                          | 601/5001 [08:52<47:57,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Step 600 Loss 0.1017\n","output_type":"stream"},{"name":"stderr","text":"Training:  14%|████▏                         | 701/5001 [09:48<46:40,  1.54it/s]","output_type":"stream"},{"name":"stdout","text":"Step 700 Loss 0.1654\n","output_type":"stream"},{"name":"stderr","text":"Training:  16%|████▊                         | 801/5001 [10:45<45:42,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Step 800 Loss 0.0605\n","output_type":"stream"},{"name":"stderr","text":"Training:  18%|█████▍                        | 901/5001 [11:41<44:38,  1.53it/s]","output_type":"stream"},{"name":"stdout","text":"Step 900 Loss 0.0786\n","output_type":"stream"},{"name":"stderr","text":"Training:  20%|█████▊                       | 1000/5001 [12:38<37:29,  1.78it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1000 Loss 0.2039\n","output_type":"stream"},{"name":"stderr","text":"Training:  22%|██████▍                      | 1101/5001 [16:42<40:55,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1100 Loss 0.0529\n","output_type":"stream"},{"name":"stderr","text":"Training:  24%|██████▉                      | 1201/5001 [17:35<39:42,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1200 Loss 0.1178\n","output_type":"stream"},{"name":"stderr","text":"Training:  26%|███████▌                     | 1301/5001 [18:29<38:25,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1300 Loss 0.0841\n","output_type":"stream"},{"name":"stderr","text":"Training:  28%|████████                     | 1401/5001 [19:23<38:27,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1400 Loss 0.0440\n","output_type":"stream"},{"name":"stderr","text":"Training:  30%|████████▋                    | 1501/5001 [20:17<37:11,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1500 Loss 0.0418\n","output_type":"stream"},{"name":"stderr","text":"Training:  32%|█████████▎                   | 1601/5001 [21:11<35:15,  1.61it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1600 Loss 0.0358\n","output_type":"stream"},{"name":"stderr","text":"Training:  34%|█████████▊                   | 1701/5001 [22:05<34:35,  1.59it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1700 Loss 0.0471\n","output_type":"stream"},{"name":"stderr","text":"Training:  36%|██████████▍                  | 1801/5001 [22:59<33:20,  1.60it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1800 Loss 0.0325\n","output_type":"stream"},{"name":"stderr","text":"Training:  38%|███████████                  | 1901/5001 [23:52<32:36,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Step 1900 Loss 0.1384\n","output_type":"stream"},{"name":"stderr","text":"Training:  40%|███████████▌                 | 2000/5001 [24:46<26:43,  1.87it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2000 Loss 0.0362\n","output_type":"stream"},{"name":"stderr","text":"Training:  42%|████████████▏                | 2101/5001 [28:51<30:54,  1.56it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2100 Loss 0.0768\n","output_type":"stream"},{"name":"stderr","text":"Training:  44%|████████████▊                | 2201/5001 [29:46<29:40,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2200 Loss 0.0654\n","output_type":"stream"},{"name":"stderr","text":"Training:  46%|█████████████▎               | 2301/5001 [30:41<28:32,  1.58it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2300 Loss 0.0398\n","output_type":"stream"},{"name":"stderr","text":"Training:  48%|█████████████▉               | 2401/5001 [31:36<27:32,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2400 Loss 0.0726\n","output_type":"stream"},{"name":"stderr","text":"Training:  50%|██████████████▌              | 2501/5001 [32:31<26:34,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2500 Loss 0.0479\n","output_type":"stream"},{"name":"stderr","text":"Training:  52%|███████████████              | 2601/5001 [33:26<25:26,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2600 Loss 0.1479\n","output_type":"stream"},{"name":"stderr","text":"Training:  54%|███████████████▋             | 2701/5001 [34:20<24:25,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2700 Loss 0.0757\n","output_type":"stream"},{"name":"stderr","text":"Training:  56%|████████████████▏            | 2801/5001 [35:15<24:19,  1.51it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2800 Loss 0.1063\n","output_type":"stream"},{"name":"stderr","text":"Training:  58%|████████████████▊            | 2901/5001 [36:10<22:15,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 2900 Loss 0.0832\n","output_type":"stream"},{"name":"stderr","text":"Training:  60%|█████████████████▍           | 3000/5001 [37:05<18:11,  1.83it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3000 Loss 0.0340\n","output_type":"stream"},{"name":"stderr","text":"Training:  62%|█████████████████▉           | 3101/5001 [41:19<23:10,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3100 Loss 0.0521\n","output_type":"stream"},{"name":"stderr","text":"Training:  64%|██████████████████▌          | 3201/5001 [42:24<22:01,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3200 Loss 0.0461\n","output_type":"stream"},{"name":"stderr","text":"Training:  66%|███████████████████▏         | 3301/5001 [43:28<20:42,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3300 Loss 0.0756\n","output_type":"stream"},{"name":"stderr","text":"Training:  68%|███████████████████▋         | 3401/5001 [44:32<19:20,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3400 Loss 0.0421\n","output_type":"stream"},{"name":"stderr","text":"Training:  70%|████████████████████▎        | 3501/5001 [45:36<18:12,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3500 Loss 0.0242\n","output_type":"stream"},{"name":"stderr","text":"Training:  72%|████████████████████▉        | 3601/5001 [46:41<17:05,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3600 Loss 0.0382\n","output_type":"stream"},{"name":"stderr","text":"Training:  74%|█████████████████████▍       | 3701/5001 [47:45<15:47,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3700 Loss 0.0703\n","output_type":"stream"},{"name":"stderr","text":"Training:  76%|██████████████████████       | 3801/5001 [48:49<14:42,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3800 Loss 0.0610\n","output_type":"stream"},{"name":"stderr","text":"Training:  78%|██████████████████████▌      | 3901/5001 [49:53<13:23,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Step 3900 Loss 0.0396\n","output_type":"stream"},{"name":"stderr","text":"Training:  80%|███████████████████████▏     | 4000/5001 [50:57<10:39,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4000 Loss 0.0769\n","output_type":"stream"},{"name":"stderr","text":"Training:  82%|███████████████████████▊     | 4101/5001 [55:11<11:04,  1.35it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4100 Loss 0.2542\n","output_type":"stream"},{"name":"stderr","text":"Training:  84%|████████████████████████▎    | 4201/5001 [56:15<09:49,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4200 Loss 0.1028\n","output_type":"stream"},{"name":"stderr","text":"Training:  86%|████████████████████████▉    | 4301/5001 [57:19<08:32,  1.36it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4300 Loss 0.0374\n","output_type":"stream"},{"name":"stderr","text":"Training:  88%|█████████████████████████▌   | 4401/5001 [58:23<07:15,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4400 Loss 0.0304\n","output_type":"stream"},{"name":"stderr","text":"Training:  90%|██████████████████████████   | 4501/5001 [59:28<06:04,  1.37it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4500 Loss 0.0538\n","output_type":"stream"},{"name":"stderr","text":"Training:  92%|████████████████████████▊  | 4601/5001 [1:00:32<04:49,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4600 Loss 0.0261\n","output_type":"stream"},{"name":"stderr","text":"Training:  94%|█████████████████████████▍ | 4701/5001 [1:01:36<03:37,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4700 Loss 0.0347\n","output_type":"stream"},{"name":"stderr","text":"Training:  96%|█████████████████████████▉ | 4801/5001 [1:02:40<02:25,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4800 Loss 0.0454\n","output_type":"stream"},{"name":"stderr","text":"Training:  98%|██████████████████████████▍| 4901/5001 [1:03:44<01:12,  1.38it/s]","output_type":"stream"},{"name":"stdout","text":"Step 4900 Loss 0.1397\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████████████████████▉| 5000/5001 [1:04:48<00:00,  1.57it/s]","output_type":"stream"},{"name":"stdout","text":"Step 5000 Loss 0.0552\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|███████████████████████████| 5001/5001 [1:07:58<00:00,  1.23it/s]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Load the saved EMA model checkpoint\nckpt_path = \"./results/otcfm/otcfm_ham10000_weights_step_5000.pt\"\ncheckpoint = torch.load(ckpt_path, map_location=device)\nstate_dict = checkpoint[\"ema_model\"]\nnet_model.load_state_dict(state_dict)\nnet_model.eval()\n\n# Generate images and save them (the function generates a grid image and writes it to disk)\ngenerate_samples(net_model, \"./results/otcfm\", 5000)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T23:45:02.206239Z","iopub.execute_input":"2025-02-21T23:45:02.206598Z","iopub.status.idle":"2025-02-21T23:46:37.390359Z","shell.execute_reply.started":"2025-02-21T23:45:02.206567Z","shell.execute_reply":"2025-02-21T23:46:37.389698Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-9fbef2cd7b97>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(ckpt_path, map_location=device)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"from cleanfid import fid\n\ndef gen_images_for_fid(unused):\n    with torch.no_grad():\n        x = torch.randn(BATCH_SIZE_FID, 3, IMAGE_SIZE, IMAGE_SIZE, device=device)\n        # Generate images unconditionally (remove 'condition' if not used)\n        if INTEGRATION_METHOD == \"euler\":\n            t_span = torch.linspace(0, 1, INTEGRATION_STEPS + 1, device=device)\n            traj = net_model.trajectory(x, t_span=t_span)\n        else:\n            t_span = torch.linspace(0, 1, 2, device=device)\n            traj = odeint(lambda t, x: net_model(t, x), x, t_span, rtol=TOL, atol=TOL, method=INTEGRATION_METHOD)\n        traj = traj[-1, :]\n        return (traj * 127.5 + 128).clamp(0, 255).to(torch.uint8)\n\nfid_score = fid.compute_fid(\n    gen=gen_images_for_fid,\n    dataset_name=\"ham10000\",  # You'd need to set this up to point to your reference data.\n    batch_size=BATCH_SIZE_FID,\n    dataset_res=IMAGE_SIZE,\n    num_gen=NUM_GEN,\n    dataset_split=\"train\",  # Adjust as needed.\n    mode=\"legacy_tensorflow\",\n)\nprint(\"FID:\", fid_score)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-21T23:50:33.311898Z","iopub.execute_input":"2025-02-21T23:50:33.312189Z","iopub.status.idle":"2025-02-21T23:50:44.573551Z","shell.execute_reply.started":"2025-02-21T23:50:33.312169Z","shell.execute_reply":"2025-02-21T23:50:44.572097Z"}},"outputs":[{"name":"stdout","text":"compute FID of a model with ham10000-128 statistics\ndownloading statistics to /usr/local/lib/python3.10/dist-packages/cleanfid/stats/ham10000_legacy_tensorflow_train_128.npz\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-8-8977cf086fc2>\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtraj\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m127.5\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m fid_score = fid.compute_fid(\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mgen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgen_images_for_fid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"ham10000\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# You'd need to set this up to point to your reference data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/fid.py\u001b[0m in \u001b[0;36mcompute_fid\u001b[0;34m(fdir1, fdir2, gen, mode, model_name, num_workers, batch_size, device, dataset_name, dataset_res, dataset_split, num_gen, z_dim, custom_feat_extractor, verbose, custom_image_tranform, custom_fn_resize, use_dataparallel)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"compute FID of a model with {dataset_name}-{dataset_res} statistics\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m         score = fid_model(gen, dataset_name, dataset_res, dataset_split,\n\u001b[0m\u001b[1;32m    526\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeat_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_gen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/fid.py\u001b[0m in \u001b[0;36mfid_model\u001b[0;34m(G, dataset_name, dataset_res, dataset_split, model, model_name, z_dim, num_gen, mode, num_workers, batch_size, device, verbose, custom_image_tranform, custom_fn_resize)\u001b[0m\n\u001b[1;32m    245\u001b[0m               custom_image_tranform=None, custom_fn_resize=None):\n\u001b[1;32m    246\u001b[0m     \u001b[0;31m# Load reference FID statistics (download if needed)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m     ref_mu, ref_sigma = get_reference_statistics(dataset_name, dataset_res,\n\u001b[0m\u001b[1;32m    248\u001b[0m                             \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                             seed=0, split=dataset_split)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/features.py\u001b[0m in \u001b[0;36mget_reference_statistics\u001b[0;34m(name, res, mode, model_name, seed, split, metric)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mmod_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleanfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mstats_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"stats\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_download_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstats_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mu\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sigma\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cleanfid/downloads_helper.py\u001b[0m in \u001b[0;36mcheck_download_url\u001b[0;34m(local_folder, url)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakedirs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"downloading statistics to {local_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlocal_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;31m# request was successfully received, understood, and accepted.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             response = self.parent.error(\n\u001b[0m\u001b[1;32m    635\u001b[0m                 'http', request, response, code, msg, hdrs)\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"],"ename":"HTTPError","evalue":"HTTP Error 404: Not Found","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}