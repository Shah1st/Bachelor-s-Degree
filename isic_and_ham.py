{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":63056,"databundleVersionId":9094797,"sourceType":"competition"},{"sourceId":104884,"sourceType":"datasetVersion","datasetId":54339}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"script","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-18T01:03:09.846013Z\",\"iopub.execute_input\":\"2025-05-18T01:03:09.846231Z\",\"iopub.status.idle\":\"2025-05-18T01:03:37.785712Z\",\"shell.execute_reply.started\":\"2025-05-18T01:03:09.846206Z\",\"shell.execute_reply\":\"2025-05-18T01:03:37.785015Z\"}}\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nimport cv2\nimport h5py\nfrom PIL import Image\nimport os\nimport time\nfrom sklearn.metrics import roc_auc_score, f1_score\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import models, transforms\nfrom transformers import ViTModel, ViTImageProcessor\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import WandbLogger\nimport wandb\nimport pickle\nimport json\nfrom pathlib import Path\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-18T01:03:37.786461Z\",\"iopub.execute_input\":\"2025-05-18T01:03:37.787087Z\",\"iopub.status.idle\":\"2025-05-18T01:03:38.423606Z\",\"shell.execute_reply.started\":\"2025-05-18T01:03:37.787057Z\",\"shell.execute_reply\":\"2025-05-18T01:03:38.423078Z\"}}\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nhugginface_key = user_secrets.get_secret(\"hugginface_key\")\nwandb_key = user_secrets.get_secret(\"wandb_key\")\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-18T01:03:38.425036Z\",\"iopub.execute_input\":\"2025-05-18T01:03:38.425258Z\",\"iopub.status.idle\":\"2025-05-18T01:03:38.474670Z\",\"shell.execute_reply.started\":\"2025-05-18T01:03:38.425241Z\",\"shell.execute_reply\":\"2025-05-18T01:03:38.473914Z\"}}\n# Function to save test split indices\ndef save_test_split_indices(train_df, val_df, test_df, dataset_name, save_dir=\"/kaggle/working/test_splits\"):\n    \"\"\"Save train/val/test dataframe indices for reproducibility across experiments\"\"\"\n    # Create directory if it doesn't exist\n    Path(save_dir).mkdir(exist_ok=True, parents=True)\n    \n    # Create dictionary with indices for each split\n    splits = {\n        \"train_indices\": train_df.index.tolist(),\n        \"val_indices\": val_df.index.tolist(),\n        \"test_indices\": test_df.index.tolist()\n    }\n    \n    # Save as pickle\n    pickle_path = f\"{save_dir}/{dataset_name}_split_indices.pkl\"\n    with open(pickle_path, 'wb') as f:\n        pickle.dump(splits, f)\n    \n    # Also save as JSON for easier inspection/sharing\n    json_path = f\"{save_dir}/{dataset_name}_split_indices.json\"\n    with open(json_path, 'w') as f:\n        json.dump(splits, f)\n    \n    print(f\"Split indices for {dataset_name} saved to {pickle_path} and {json_path}\")\n    return pickle_path, json_path\n\n# Function to load saved split indices\ndef load_split_indices(dataset_name, save_dir=\"/kaggle/working/test_splits\"):\n    \"\"\"Load previously saved split indices\"\"\"\n    pickle_path = f\"{save_dir}/{dataset_name}_split_indices.pkl\"\n    json_path = f\"{save_dir}/{dataset_name}_split_indices.json\"\n    \n    # Try to load pickle first\n    if Path(pickle_path).exists():\n        with open(pickle_path, 'rb') as f:\n            splits = pickle.load(f)\n        print(f\"Loaded split indices from {pickle_path}\")\n        return splits\n    # Fall back to JSON\n    elif Path(json_path).exists():\n        with open(json_path, 'r') as f:\n            splits = json.load(f)\n        print(f\"Loaded split indices from {json_path}\")\n        return splits\n    else:\n        raise FileNotFoundError(f\"No saved split indices found for {dataset_name}\")\n\n# Dataset classes\nclass ISICDataset(Dataset):\n    def __init__(self, df, hdf5_file, processor, model_type=\"vit\", neg_sample=None, pos_sample=None, seed=42):\n        self.hdf5_file = hdf5_file\n        self.processor = processor\n        self.model_type = model_type\n        self.seed = seed\n        \n        # Apply balanced sampling only for training\n        if neg_sample is not None and pos_sample is not None:\n            self.df = self._balance_sampling(df, neg_sample, pos_sample)\n        else:\n            self.df = df.reset_index(drop=True)\n\n    def _balance_sampling(self, df, neg_sample, pos_sample):\n        positive_df = df.query(\"target == 0\").sample(frac=neg_sample, random_state=self.seed)\n        negative_df = df.query(\"target == 1\").sample(frac=pos_sample, replace=True, random_state=self.seed)\n        balanced_df = pd.concat([positive_df, negative_df], axis=0).sample(frac=1.0, random_state=self.seed)\n        return balanced_df.reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        isic_id = self.df.iloc[idx]['isic_id']\n        label = torch.tensor(self.df.iloc[idx]['target'], dtype=torch.float32)\n\n        image_data = self.hdf5_file[isic_id][()]\n        image_array = np.frombuffer(image_data, np.uint8)\n        image = cv2.cvtColor(cv2.imdecode(image_array, cv2.IMREAD_COLOR), cv2.COLOR_BGR2RGB)\n\n        if self.model_type == \"vit\":\n            # For ViT, use the processor directly\n            inputs = self.processor(images=image, return_tensors=\"pt\")\n            image = inputs['pixel_values'].squeeze()\n        else:\n            # For EfficientNet, convert numpy array to PIL image and apply transforms\n            image = self.processor(Image.fromarray(image))\n\n        return image, label\n\nclass HAM10000Dataset(Dataset):\n    def __init__(self, df, processor, model_type=\"vit\", seed=42):\n        self.processor = processor\n        self.model_type = model_type\n        self.seed = seed\n        self.df = df.reset_index(drop=True)\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        image_path = row['image_path']\n        label = torch.tensor(row['target'], dtype=torch.float32)\n\n        # Load and process the image\n        try:\n            image = cv2.imread(image_path)\n            if image is None:\n                raise ValueError(f\"Could not load image at {image_path}\")\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        except Exception as e:\n            print(f\"Error loading image {image_path}: {e}\")\n            # Provide a blank image as fallback\n            image = np.zeros((224, 224, 3), dtype=np.uint8)\n\n        if self.model_type == \"vit\":\n            # Process for ViT model\n            inputs = self.processor(images=image, return_tensors=\"pt\")\n            image = inputs['pixel_values'].squeeze()\n        else:\n            # Process for EfficientNet model\n            image = self.processor(Image.fromarray(image))\n\n        return image, label\n\n# Lightning Module\nclass SkinLesionClassifier(pl.LightningModule):\n    def __init__(self, model_name=\"vit\", learning_rate=1e-4, pos_weight=1.0):\n        super().__init__()\n        self.save_hyperparameters()\n        self.model_name = model_name\n        self.learning_rate = learning_rate\n        \n        # Model initialization\n        if model_name == \"vit\":\n            self.model = ViTModel.from_pretrained('google/vit-base-patch16-224')\n            self.classifier = nn.Linear(self.model.config.hidden_size, 1)\n        elif model_name == \"effnet_b0\":\n            self.model = models.efficientnet_b0(pretrained=True)\n            self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, 1)\n            self.classifier = self.model.classifier[1]\n        elif model_name == \"effnet_b4\":\n            self.model = models.efficientnet_b4(pretrained=True)\n            self.model.classifier[1] = nn.Linear(self.model.classifier[1].in_features, 1)\n            self.classifier = self.model.classifier[1]\n        else:\n            raise ValueError(\"Model name must be 'vit', 'effnet_b0', or 'effnet_b4'\")\n            \n        self.criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(pos_weight))\n        \n        # For validation metrics tracking\n        self.validation_step_outputs = []\n        self.test_step_outputs = []\n        \n    def forward(self, x):\n        if self.model_name == \"vit\":\n            outputs = self.model(pixel_values=x)\n            x = outputs.last_hidden_state[:, 0, :]  # CLS token\n            x = self.classifier(x)\n        else:\n            x = self.model(x)\n        return x.squeeze()\n    \n    def training_step(self, batch, batch_idx):\n        images, labels = batch\n        logits = self(images)\n        loss = self.criterion(logits, labels)\n        \n        # Calculate metrics (consistent with validation)\n        probs = torch.sigmoid(logits)\n        preds = (probs > 0.5).float()\n        \n        acc = (preds == labels).float().mean()\n        f1 = self._calculate_f1(labels, preds)\n        \n        # Log metrics\n        self.log('train_loss', loss, prog_bar=True)\n        self.log('train_acc', acc, prog_bar=True)\n        self.log('train_f1', f1, prog_bar=True)\n        \n        return loss\n        \n    def validation_step(self, batch, batch_idx):\n        images, labels = batch\n        logits = self(images)\n        loss = self.criterion(logits, labels)\n    \n        # Apply sigmoid for predictions\n        probs = torch.sigmoid(logits)\n        preds = (probs > 0.5).float()\n        \n        # Calculate metrics\n        acc = (preds == labels).float().mean()\n        f1 = self._calculate_f1(labels, preds)\n        \n        # Log metrics\n        self.log('val_loss', loss, prog_bar=True)\n        self.log('val_acc', acc, prog_bar=True)\n        self.log('val_f1', f1, prog_bar=True)\n        \n        # Store probabilities, not logits, for AUC calculation\n        self.validation_step_outputs.append({\n            'probs': probs,  # Store probabilities for AUC \n            'preds': preds,  # Store binary predictions for other metrics\n            'labels': labels,\n            'logits': logits  # Store logits for debugging\n        })\n        \n        return loss\n    \n    def on_validation_epoch_end(self):\n        # Collect all outputs\n        all_probs = torch.cat([x['probs'] for x in self.validation_step_outputs])\n        all_preds = torch.cat([x['preds'] for x in self.validation_step_outputs])\n        all_labels = torch.cat([x['labels'] for x in self.validation_step_outputs])\n        \n        # Print validation set statistics\n        pos_count = all_labels.sum().item()\n        total = len(all_labels)\n        pos_ratio = pos_count / total\n        print(f\"Validation set: {pos_count}/{total} positive samples ({pos_ratio:.2%})\")\n        \n        # Print prediction statistics\n        pred_pos = all_preds.sum().item()\n        pred_ratio = pred_pos / total\n        print(f\"Predictions: {pred_pos}/{total} predicted positive ({pred_ratio:.2%})\")\n        \n        # Print confusion matrix\n        from sklearn.metrics import confusion_matrix\n        cm = confusion_matrix(all_labels.cpu().numpy(), all_preds.cpu().numpy())\n        print(f\"Confusion Matrix:\\n{cm}\")\n        \n        # Calculate AUC using probabilities\n        try:\n            auc = roc_auc_score(all_labels.cpu().numpy(), all_probs.cpu().numpy())\n            self.log('val_auc', auc, prog_bar=True)\n        except Exception as e:\n            print(f\"Error calculating AUC: {e}\")\n        \n        # Try to find optimal threshold\n        try:\n            from sklearn.metrics import f1_score\n            thresholds = np.arange(0.1, 0.9, 0.05)\n            best_f1 = 0\n            best_thresh = 0.5\n            \n            for thresh in thresholds:\n                thresh_preds = (all_probs.cpu().numpy() > thresh).astype(float)\n                f1 = f1_score(all_labels.cpu().numpy(), thresh_preds)\n                if f1 > best_f1:\n                    best_f1 = f1\n                    best_thresh = thresh\n            \n            print(f\"Best threshold: {best_thresh:.2f}, F1: {best_f1:.4f}\")\n            \n            # Log optimal threshold stats\n            self.log('val_f1_optimal', best_f1, prog_bar=True)\n            self.log('val_optimal_threshold', best_thresh, prog_bar=False)\n            \n            # Recalculate metrics with optimal threshold\n            optimal_preds = (all_probs.cpu().numpy() > best_thresh).astype(float)\n            cm_optimal = confusion_matrix(all_labels.cpu().numpy(), optimal_preds)\n            print(f\"Confusion Matrix with optimal threshold:\\n{cm_optimal}\")\n            \n            from sklearn.metrics import precision_score, recall_score\n            precision = precision_score(all_labels.cpu().numpy(), optimal_preds)\n            recall = recall_score(all_labels.cpu().numpy(), optimal_preds)\n            print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {best_f1:.4f}\")\n            \n        except Exception as e:\n            print(f\"Error finding optimal threshold: {e}\")\n        \n        # Clear outputs\n        self.validation_step_outputs.clear()\n        \n    def test_step(self, batch, batch_idx):\n        images, labels = batch\n        logits = self(images)\n        loss = self.criterion(logits, labels)\n        \n        # Calculate metrics (consistent with validation)\n        probs = torch.sigmoid(logits)\n        preds = (probs > 0.5).float()\n        \n        acc = (preds == labels).float().mean()\n        f1 = self._calculate_f1(labels, preds)\n        \n        # Log metrics\n        self.log('test_loss', loss)\n        self.log('test_acc', acc)\n        self.log('test_f1', f1)\n        \n        # Store for epoch end calculations\n        self.test_step_outputs.append({\n            'probs': probs,\n            'preds': preds,\n            'labels': labels\n        })\n        \n        return loss\n    \n    def on_test_epoch_end(self):\n        # Collect all outputs\n        all_probs = torch.cat([x['probs'] for x in self.test_step_outputs])\n        all_preds = torch.cat([x['preds'] for x in self.test_step_outputs])\n        all_labels = torch.cat([x['labels'] for x in self.test_step_outputs])\n        \n        # Print test set statistics\n        pos_count = all_labels.sum().item()\n        total = len(all_labels)\n        print(f\"Test set: {pos_count}/{total} positive samples ({pos_count/total:.2%})\")\n        \n        # Print prediction statistics\n        pred_pos = all_preds.sum().item()\n        print(f\"Predictions: {pred_pos}/{total} predicted positive ({pred_pos/total:.2%})\")\n        \n        # Print confusion matrix\n        from sklearn.metrics import confusion_matrix\n        cm = confusion_matrix(all_labels.cpu().numpy(), all_preds.cpu().numpy())\n        print(f\"Confusion Matrix:\\n{cm}\")\n        \n        # Calculate AUC\n        try:\n            auc = roc_auc_score(all_labels.cpu().numpy(), all_probs.cpu().numpy())\n            self.log('test_auc', auc)\n        except:\n            pass\n        \n        # Clear outputs\n        self.test_step_outputs.clear()\n    \n    def _calculate_f1(self, y_true, y_pred):\n        tp = (y_true * y_pred).sum().float()\n        fp = ((1 - y_true) * y_pred).sum().float()\n        fn = (y_true * (1 - y_pred)).sum().float()\n        \n        precision = tp / (tp + fp + 1e-8)\n        recall = tp / (tp + fn + 1e-8)\n        \n        f1 = 2 * (precision * recall) / (precision + recall + 1e-8)\n        return f1\n    \n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n            optimizer, mode='min', factor=0.5, patience=3, verbose=True\n        )\n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\n                \"scheduler\": scheduler,\n                \"monitor\": \"val_loss\",\n                \"frequency\": 1\n            },\n        }\n\n# Data preparation functions\ndef prepare_isic_data(train_hdf5_path, train_metadata_path, use_saved_splits=True):\n    \"\"\"Prepare ISIC dataset with option to use saved splits\"\"\"\n    # Load metadata\n    train_hdf5 = h5py.File(train_hdf5_path, 'r')\n    train_metadata = pd.read_csv(train_metadata_path)\n    \n    # Try to load saved splits if requested\n    if use_saved_splits:\n        try:\n            splits = load_split_indices(\"isic\")\n            # Convert indices to integer if they're strings (can happen with JSON)\n            train_indices = [int(idx) for idx in splits[\"train_indices\"]]\n            val_indices = [int(idx) for idx in splits[\"val_indices\"]]\n            test_indices = [int(idx) for idx in splits[\"test_indices\"]]\n            \n            # Use .iloc for positional indexing instead of .loc\n            train_df = train_metadata.iloc[train_indices].reset_index(drop=True)\n            val_df = train_metadata.iloc[val_indices].reset_index(drop=True)\n            test_df = train_metadata.iloc[test_indices].reset_index(drop=True)\n            print(\"Using saved ISIC dataset splits\")\n            return train_df, val_df, test_df, train_hdf5\n        except FileNotFoundError:\n            print(\"No saved splits found, creating new splits\")\n    \n    # Create new splits\n    # First split into train+val and test\n    train_val_df, test_df = train_test_split(train_metadata, test_size=0.15, random_state=42)\n    # Then split train+val into train and validation\n    train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n    \n    # Save the splits\n    save_test_split_indices(train_df, val_df, test_df, \"isic\")\n    \n    print(f\"ISIC Dataset: Training: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n    \n    return train_df, val_df, test_df, train_hdf5\n\ndef prepare_ham10000_data(ham_metadata_path, img_dir1, img_dir2, use_saved_splits=True):\n    \"\"\"Prepare HAM10000 dataset with option to use saved splits\"\"\"\n    # Load metadata\n    df = pd.read_csv(ham_metadata_path)\n    \n    # Dictionary to map lesion types to benign or malignant\n    benign_types = ['nv', 'bkl', 'akiec', 'vasc', 'df']\n    malignant_types = ['mel', 'bcc']\n    \n    # Add binary target column: 0 for benign, 1 for malignant\n    df['target'] = df['dx'].apply(lambda x: 0 if x in benign_types else 1)\n    \n    # Function to locate the image path\n    def get_image_path(image_id):\n        filename = f\"{image_id}.jpg\"\n        if os.path.exists(os.path.join(img_dir1, filename)):\n            return os.path.join(img_dir1, filename)\n        elif os.path.exists(os.path.join(img_dir2, filename)):\n            return os.path.join(img_dir2, filename)\n        else:\n            return None  # In case the image is missing\n    \n    df['image_path'] = df['image_id'].apply(get_image_path)\n    \n    # Remove any rows with missing images\n    df = df[df['image_path'].notna()].reset_index(drop=True)\n    \n    # Try to load saved splits if requested\n    if use_saved_splits:\n        try:\n            splits = load_split_indices(\"ham10000\")\n            # Convert indices to integer if they're strings (can happen with JSON)\n            train_indices = [int(idx) for idx in splits[\"train_indices\"]]\n            val_indices = [int(idx) for idx in splits[\"val_indices\"]]\n            test_indices = [int(idx) for idx in splits[\"test_indices\"]]\n            \n            # Use .iloc for positional indexing\n            train_df = df.iloc[train_indices].reset_index(drop=True)\n            val_df = df.iloc[val_indices].reset_index(drop=True)\n            test_df = df.iloc[test_indices].reset_index(drop=True)\n            print(\"Using saved HAM10000 dataset splits\")\n            return train_df, val_df, test_df\n        except FileNotFoundError:\n            print(\"No saved splits found, creating new splits\")\n    \n    # Create new splits\n    # First split into train+val and test\n    train_val_df, test_df = train_test_split(df, test_size=0.15, random_state=42)\n    # Then split train+val into train and validation\n    train_df, val_df = train_test_split(train_val_df, test_size=0.15, random_state=42)\n    \n    # Save the splits\n    save_test_split_indices(train_df, val_df, test_df, \"ham10000\")\n    \n    print(f\"HAM10000 Dataset: Training: {len(train_df)}, Validation: {len(val_df)}, Test: {len(test_df)}\")\n    \n    return train_df, val_df, test_df\n\n# Data module\nclass SkinLesionDataModule(pl.LightningDataModule):\n    def __init__(self, dataset_name, model_name, batch_size=16, num_workers=4, use_saved_splits=True):\n        super().__init__()\n        self.dataset_name = dataset_name\n        self.model_name = model_name\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.use_saved_splits = use_saved_splits\n        \n        # Set up preprocessing based on model type\n        if model_name == \"vit\":\n            self.processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n        else:\n            target_size = 224 if model_name == \"effnet_b0\" else 380\n            self.processor = transforms.Compose([\n                transforms.Resize(target_size),\n                transforms.ToTensor(),\n                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n            ])\n        \n        # Paths for ISIC dataset\n        self.train_hdf5_path = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\n        self.train_metadata_path = '/kaggle/input/isic-2024-challenge/train-metadata.csv'\n        \n        # Paths for HAM10000 dataset\n        self.ham_metadata_path = '/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_metadata.csv'\n        self.img_dir1 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_1\"\n        self.img_dir2 = \"/kaggle/input/skin-cancer-mnist-ham10000/HAM10000_images_part_2\"\n    \n    def setup(self, stage=None):\n        if self.dataset_name == \"isic\":\n            self.train_df, self.val_df, self.test_df, self.train_hdf5 = prepare_isic_data(\n                self.train_hdf5_path, self.train_metadata_path, \n                use_saved_splits=self.use_saved_splits\n            )\n            \n            # Create datasets\n            self.train_dataset = ISICDataset(\n                self.train_df, self.train_hdf5, self.processor, \n                model_type=self.model_name, neg_sample=0.01, pos_sample=5.0\n            )\n            self.val_dataset = ISICDataset(\n                self.val_df, self.train_hdf5, self.processor, \n                model_type=self.model_name\n            )\n            self.test_dataset = ISICDataset(\n                self.test_df, self.train_hdf5, self.processor, \n                model_type=self.model_name\n            )\n            \n        elif self.dataset_name == \"ham10000\":\n            self.train_df, self.val_df, self.test_df = prepare_ham10000_data(\n                self.ham_metadata_path, self.img_dir1, self.img_dir2,\n                use_saved_splits=self.use_saved_splits\n            )\n            \n            # Create datasets\n            self.train_dataset = HAM10000Dataset(\n                self.train_df, self.processor, model_type=self.model_name\n            )\n            self.val_dataset = HAM10000Dataset(\n                self.val_df, self.processor, model_type=self.model_name\n            )\n            self.test_dataset = HAM10000Dataset(\n                self.test_df, self.processor, model_type=self.model_name\n            )\n    \n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset, batch_size=self.batch_size, \n            shuffle=True, num_workers=self.num_workers, pin_memory=True\n        )\n    \n    def val_dataloader(self):\n        return DataLoader(\n            self.val_dataset, batch_size=self.batch_size, \n            shuffle=False, num_workers=self.num_workers, pin_memory=True\n        )\n    \n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset, batch_size=self.batch_size, \n            shuffle=False, num_workers=self.num_workers, pin_memory=True\n        )\n\n\n\n# %% [code]\n# Training function with wandb\ndef train_model(dataset_name, model_name, max_epochs=5, wandb_api_key=None):\n    # Set up experiment name\n    experiment_name = f\"{dataset_name}_{model_name}\"\n    \n    # Initialize wandb if API key is provided\n    if wandb_api_key:\n        wandb.login(key=wandb_api_key)\n        logger = WandbLogger(\n            project=\"skin-cancer-classification\",\n            name=experiment_name,\n            log_model=\"all\"\n        )\n    else:\n        from pytorch_lightning.loggers import TensorBoardLogger\n        logger = TensorBoardLogger(\"/kaggle/working/logs\", name=experiment_name)\n    \n    # Initialize data module\n    dm = SkinLesionDataModule(dataset_name, model_name, batch_size=16)\n    \n    # Initialize model\n    model = SkinLesionClassifier(model_name=model_name)\n    \n    # Setup callbacks\n    checkpoint_callback = ModelCheckpoint(\n        dirpath=f\"/kaggle/working/{experiment_name}\",\n        filename=\"{epoch}-{val_loss:.2f}-{val_acc:.2f}\",\n        save_top_k=1,\n        verbose=True,\n        monitor='val_loss',\n        mode='min'\n    )\n    \n    early_stopping = EarlyStopping(\n        monitor='val_loss',\n        patience=5,\n        verbose=True,\n        mode='min'\n    )\n    \n    # Initialize trainer\n    trainer = pl.Trainer(\n        max_epochs=max_epochs,\n        accelerator='gpu',\n        devices=1,\n        callbacks=[checkpoint_callback, early_stopping],\n        logger=logger,\n        log_every_n_steps=50,\n        deterministic=True,\n        #precision=\"16-mixed\"  # Use mixed precision for faster training\n    )\n    \n    # Start time\n    start_time = time.time()\n    \n    # Train model\n    trainer.fit(model, dm)\n    \n    # End time\n    training_time = (time.time() - start_time) / 60  # minutes\n    print(f\"Training completed in {training_time:.2f} minutes\")\n    \n    # Test model\n    trainer.test(model, datamodule=dm)\n    \n    # Save final model\n    final_model_path = f\"/kaggle/working/{experiment_name}_final.pth\"\n    torch.save(model.state_dict(), final_model_path)\n    print(f\"Final model saved to {final_model_path}\")\n    \n    # If using wandb, finish run\n    if wandb_api_key:\n        wandb.finish()\n    \n    return model, final_model_path, checkpoint_callback.best_model_path\n\n# Function to upload model to Hugging Face\ndef upload_to_huggingface(model_path, repo_id, token):\n    try:\n        from huggingface_hub import HfApi\n        api = HfApi()\n        \n        # Upload the model file\n        api.upload_file(\n            path_or_fileobj=model_path,\n            path_in_repo=os.path.basename(model_path),\n            repo_id=repo_id,\n            token=token\n        )\n        print(f\"Successfully uploaded {model_path} to {repo_id}\")\n        return True\n    except Exception as e:\n        print(f\"Error uploading to Hugging Face: {e}\")\n        return False\n\n\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2025-05-18T01:03:38.475499Z\",\"iopub.execute_input\":\"2025-05-18T01:03:38.475768Z\",\"execution_failed\":\"2025-05-18T02:05:44.517Z\"}}\n# Main execution\ndef main():\n    # Configuration\n    wandb_api_key = wandb_key  # Replace with your Wandb API key or None to disable\n    hf_token = hugginface_key  # Replace with your Hugging Face token or None to disable\n    hf_repo_base = \"Shah1st/skin-cancer-classification-models\"  # Replace with your repo\n    \n    # Models to train\n    models_to_train = [\n        {\"dataset\": \"isic\", \"model\": \"vit\", \"epochs\": 5},\n        {\"dataset\": \"isic\", \"model\": \"effnet_b0\", \"epochs\": 5},\n        {\"dataset\": \"isic\", \"model\": \"effnet_b4\", \"epochs\": 5},\n        {\"dataset\": \"ham10000\", \"model\": \"vit\", \"epochs\": 5},\n        {\"dataset\": \"ham10000\", \"model\": \"effnet_b0\", \"epochs\": 5},\n        {\"dataset\": \"ham10000\", \"model\": \"effnet_b4\", \"epochs\": 5}\n    ]\n    \n    # Train all models\n    model_paths = []\n    for config in models_to_train:\n        print(f\"\\n{'='*50}\")\n        print(f\"Training {config['model']} on {config['dataset']} dataset\")\n        print(f\"{'='*50}\\n\")\n        \n        _, final_model_path, best_model_path = train_model(\n            config['dataset'], config['model'], config['epochs'], wandb_api_key\n        )\n        \n        model_paths.append({\n            \"dataset\": config['dataset'],\n            \"model\": config['model'],\n            \"final_path\": final_model_path,\n            \"best_path\": best_model_path\n        })\n    \n    # Upload all models to Hugging Face\n    if hf_token != \"YOUR_HF_TOKEN\":  # Only if token is provided\n        for path_info in model_paths:\n            repo_id = f\"{hf_repo_base}/{path_info['dataset']}_{path_info['model']}\"\n            upload_to_huggingface(\n                path_info[\"best_path\"], \n                repo_id, \n                hf_token\n            )\n    else:\n        print(\"Hugging Face token not provided. Skip uploading.\")\n\nif __name__ == \"__main__\":\n    main()\n\n# %% [code]\n","metadata":{"_uuid":"8b0e1d09-af40-4183-bd87-c9bdfb8c5265","_cell_guid":"5b93087a-fdb5-4a03-b24e-b29822a9fbf1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null}]}